{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Bibliotekos",
   "id": "64fa541b7da924a3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from symbol import comparison\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from nltk.chunk.named_entity import shape\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import spacy\n",
    "from sklearn.ensemble import StackingClassifier"
   ],
   "id": "212c3ccd41ecd1ce"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Failo skaitymas",
   "id": "6e1df5f1d56310ac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# Perskaitome failÄ…\n",
    "df = pd.read_csv(\"spam.csv\", encoding=\"latin-1\")\n",
    "\n",
    "df = df.iloc[:, :2]  # pasirenkam tik pirmus du stulpelius\n",
    "df.columns = ['label', 'text']  # pervadinam, jei reikia\n",
    "df['text'] = df['text'].str.lower()\n",
    "\n",
    "print(df.info())\n"
   ],
   "id": "51b0b60b736cc802"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df['label'] = df['label'].map({'spam': 1, 'ham': 0})\n",
    "\n",
    "print(df.head())"
   ],
   "id": "df23d658c4b55dff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# SuskaiÄiuojame kiekvienÄ… klasÄ™\n",
    "counts = df['label'].value_counts(normalize=True) * 100  # procentai\n",
    "\n",
    "# Sukuriame bar plot\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.bar(['Ham', 'Spam'], counts, color=['#4C72B0', '#C44E52'], edgecolor='black')\n",
    "\n",
    "# Pridedame procentus virÅ¡ barÅ³\n",
    "for i, val in enumerate(counts):\n",
    "    plt.text(i, val + 1, f'{val:.1f}%', ha='center', fontsize=12)\n",
    "\n",
    "plt.ylabel('Procentas (%)')\n",
    "plt.ylim(0, 110)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "44b7de339e9de68"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df['word_count'] = df['text'].apply(lambda x: len([w for w in str(x).split() if w.isalpha()]))\n",
    "\n",
    "\n",
    "df['char_count'] = df['text'].apply(lambda x: len(str(x).replace(\" \", \"\")))\n",
    "\n",
    "def plot_histograms(df, suffix=\"\"):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.histplot(df, x='word_count', hue='label', bins=30, kde=False, palette={0:'skyblue',1:'orange'})\n",
    "    plt.xlabel(\"Å½odÅ¾iÅ³ skaiÄius\")\n",
    "    plt.ylabel(\"Å½inuÄiÅ³ skaiÄius\")\n",
    "    plt.title(f\"Å½inuÄiÅ³ ilgiai (Å¾odÅ¾iai)\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.histplot(df, x='char_count', hue='label', bins=30, kde=False, palette={0:'skyblue',1:'orange'})\n",
    "    plt.xlabel(\"SimboliÅ³ skaiÄius (be tarpÅ³)\")\n",
    "    plt.ylabel(\"Å½inuÄiÅ³ skaiÄius\")\n",
    "    plt.title(f\"Å½inuÄiÅ³ ilgiai (simboliai)1\")\n",
    "    plt.show()\n",
    "\n",
    "plot_histograms(df, \"(original)\")\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "def plot_wordcloud(df, label, title):\n",
    "    text = \" \".join(df[df['label'] == label]['text'])\n",
    "\n",
    "    word_freq = Counter(text.split())\n",
    "\n",
    "    wc = WordCloud(\n",
    "        width=800,\n",
    "        height=400,\n",
    "        background_color='white',\n",
    "        colormap='Reds' if label == 1 else 'Blues'\n",
    "    ).generate_from_frequencies(word_freq)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_wordcloud(df, 1, \"DaÅ¾niausi Å¾odÅ¾iai SPAM\")\n",
    "plot_wordcloud(df, 0, \"DaÅ¾niausi Å¾odÅ¾iai HAM\")\n",
    "\n",
    "def get_top_words(df, label, n=20):\n",
    "    words = \" \".join(df[df['label']==label]['text']).split()\n",
    "    counter = Counter(words)\n",
    "    return counter.most_common(n)\n",
    "\n",
    "top_spam = get_top_words(df, 1)\n",
    "top_ham = get_top_words(df, 0)\n",
    "print(\"Top SPAM:\", top_spam)\n",
    "print(\"Top HAM:\", top_ham)"
   ],
   "id": "b1fdb105089c4a06"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Sukuriame savo stop_words sÄ…raÅ¡Ä…\n",
    "my_stop_words = {\n",
    "    'the', 'a', 'an', 'and', 'or', 'in', 'on', 'of', 'to', 'for', 'is', 'are',\n",
    "    'was', 'were', 'be', 'been', 'it', 'this', 'that', 'with', 'as', 'by', 'at',\n",
    "    'from', 'about', 'into', 'up', 'out', 'so', 'if', 'then', 'but', 'you', 'your', 'have',\n",
    "    'u', 'just'\n",
    "}\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    words = str(text).lower().split()\n",
    "    filtered = [w for w in words if w not in my_stop_words]\n",
    "    return \" \".join(filtered)\n",
    "\n",
    "# Sukuriame kopijÄ… ir pritaikome funkcijÄ…\n",
    "df_sw = df.copy()\n",
    "df_sw['text'] = df_sw['text'].apply(remove_stopwords)\n"
   ],
   "id": "a6b904f20b30de02"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "def plot_wordcloud(df, label, title):\n",
    "    text = \" \".join(df[df['label'] == label]['text'])\n",
    "\n",
    "    word_freq = Counter(text.split())\n",
    "\n",
    "    wc = WordCloud(\n",
    "        width=800,\n",
    "        height=400,\n",
    "        background_color='white',\n",
    "        colormap='Reds' if label == 1 else 'Blues'\n",
    "    ).generate_from_frequencies(word_freq)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_wordcloud(df_sw, 1, \"DaÅ¾niausi Å¾odÅ¾iai SPAM\")\n",
    "plot_wordcloud(df_sw, 0, \"DaÅ¾niausi Å¾odÅ¾iai HAM\")\n"
   ],
   "id": "bcc29d6a1bcdac6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plot_histograms(df_sw, \"(be stopwords)\")\n",
    "plot_wordcloud(df_sw, 1, \"SPAM (be stopwords)\")\n",
    "plot_wordcloud(df_sw, 0, \"HAM (be stopwords)\")\n",
    "\n",
    "top_spam_sw = get_top_words(df_sw, 1)\n",
    "top_ham_sw = get_top_words(df_sw, 0)\n",
    "print(\"Top SPAM (be stopwords):\", top_spam_sw)\n",
    "print(\"Top HAM (be stopwords):\", top_ham_sw)\n"
   ],
   "id": "fa9055fcedbc626d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Vektorizavimas/mokymas\n",
   "id": "22fc7e851502d045"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Linear SVM\": LinearSVC(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=5),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5)\n",
    "}\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "def vectorize_text(df, method=\"bow\", vectorizer=None):\n",
    "    texts = df['text'].astype(str).tolist()\n",
    "\n",
    "    if method == \"bow\":\n",
    "        if vectorizer is None:\n",
    "            vectorizer = CountVectorizer()\n",
    "            X = vectorizer.fit_transform(texts)   # treniruojam + kuriam zodyna\n",
    "        else:\n",
    "            X = vectorizer.transform(texts)       # naudojam esama zodyna\n",
    "\n",
    "    elif method == \"tfidf\":\n",
    "        if vectorizer is None:\n",
    "            vectorizer = TfidfVectorizer()\n",
    "            X = vectorizer.fit_transform(texts)\n",
    "        else:\n",
    "            X = vectorizer.transform(texts)\n",
    "\n",
    "    elif method == \"spacy_w2v\":\n",
    "        # spacy nereikia vectorizer\n",
    "        X = np.array([nlp(t).vector for t in texts])\n",
    "        vectorizer = None\n",
    "    else:\n",
    "        raise ValueError(\"NeÅ¾inomas metodas\")\n",
    "\n",
    "    return X, vectorizer\n",
    "\n",
    "def train_and_evaluate(models, X_train, X_test, y_train, y_test, title=\"\"):\n",
    "    results = []\n",
    "    print(f\"\\n=== {title} ===\")\n",
    "    for name, model in models.items():\n",
    "        print(f\"ðŸ”¹ Treniruojamas: {name}\")\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        results.append((name, acc))\n",
    "        print(f\"âœ… Tikslumas: {acc:.4f}\")\n",
    "        print(classification_report(y_test, y_pred, digits=3))\n",
    "        print(\"-\"*50)\n",
    "    return pd.DataFrame(results, columns=[\"Model\", \"Accuracy\"]).sort_values(by=\"Accuracy\", ascending=False)\n",
    "\n",
    "def plot_results(df, title=\"\"):\n",
    "    df = df.sort_values(by=\"Accuracy\", ascending=True)\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.barh(df[\"Model\"], df[\"Accuracy\"], color='skyblue')\n",
    "    for i, v in enumerate(df[\"Accuracy\"]):\n",
    "        plt.text(v + 0.002, i, f\"{v:.3f}\", va='center')\n",
    "    plt.xlabel(\"Tikslumas\")\n",
    "    plt.title(title)\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
    "    plt.show()"
   ],
   "id": "a62ddadf01955566"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train/Test padalinimas bei mokymas",
   "id": "48a11c1f55507855"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "y = df['label'].values\n",
    "results_all = {}\n",
    "for method in [\"bow\", \"tfidf\", \"spacy_w2v\"]:\n",
    "    print(f\"\\n\\n### Vektorizacija: {method.upper()} ###\")\n",
    "    for data, label in [(df, \"original\"), (df_sw, \"no_stopwords\")]:\n",
    "        X, vectorizer = vectorize_text(data, method)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)\n",
    "        results = train_and_evaluate(models, X_train, X_test, y_train, y_test, title=f\"{method.upper()} - {label}\")\n",
    "        results_all[f\"{method}_{label}\"] = results\n",
    "        plot_results(results, title=f\"{method.upper()} - {label}\")"
   ],
   "id": "4299e15ce9aa7982"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "comparison_df = pd.DataFrame({\"Model\": list(models.keys())})\n",
    "for key, df_res in results_all.items():\n",
    "    comparison_df = comparison_df.merge(df_res, on=\"Model\", how=\"left\", suffixes=(\"\", f\"_{key}\"))\n",
    "\n",
    "comparison_df.columns = [\"Model\"] + [f\"Accuracy_{k}\" for k in results_all.keys()]\n",
    "\n",
    "# UÅ¾tikriname, kad stulpeliai bÅ«tÅ³ float\n",
    "for col in comparison_df.columns[1:]:\n",
    "    comparison_df[col] = comparison_df[col].astype(float)\n",
    "\n",
    "x = np.arange(len(comparison_df))\n",
    "n_methods = len(comparison_df.columns) - 1\n",
    "width = 0.8 / n_methods\n",
    "\n",
    "# GraÅ¾esnÄ— spalvÅ³ paletÄ—\n",
    "colors = [\"#4C72B0\", \"#55A868\", \"#C44E52\", \"#8172B2\", \"#CCB974\", \"#64B5CD\"]\n",
    "\n",
    "# Friendly legendos pavadinimai\n",
    "friendly_labels = {\n",
    "    \"BOW_ORIGINAL\": \"BOW su nereikÅ¡mingais Å¾odÅ¾iais\",\n",
    "    \"BOW_NO_STOPWORDS\": \"BOW be nereikÅ¡mingÅ³ Å¾odÅ¾iÅ³\",\n",
    "    \"TFIDF_ORIGINAL\": \"TFIDF su nereikÅ¡mingais Å¾odÅ¾iais\",\n",
    "    \"TFIDF_NO_STOPWORDS\": \"TFIDF be nereikÅ¡mingÅ³ Å¾odÅ¾iÅ³\",\n",
    "    \"SPACY_W2V_ORIGINAL\": \"SPACY_W2V su nereikÅ¡mingais Å¾odÅ¾iais\",\n",
    "    \"SPACY_W2V_NO_STOPWORDS\": \"SPACY_W2V be nereikÅ¡mingÅ³ Å¾odÅ¾iÅ³\"\n",
    "}\n",
    "\n",
    "x = np.arange(len(comparison_df))\n",
    "n_methods = len(comparison_df.columns) - 1\n",
    "x = np.arange(n_models)\n",
    "width = 0.8 / n_methods\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "\n",
    "for i, col in enumerate(comparison_df.columns[1:]):\n",
    "    # PaÅ¡aliname \"Accuracy_\" prefix\n",
    "    key_name = col.replace(\"Accuracy_\", \"\")\n",
    "    # Tikrai sutapimas su friendly_labels\n",
    "    label = friendly_labels.get(key_name.upper(), key_name)\n",
    "\n",
    "    plt.bar(\n",
    "        x + i * width - (width * (n_methods - 1) / 2),\n",
    "        comparison_df[col].astype(float),\n",
    "        width,\n",
    "        label=label,\n",
    "        alpha=0.9,\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=0.7,\n",
    "        color=colors[i % len(colors)]\n",
    "    )\n",
    "\n",
    "plt.xticks(x, comparison_df[\"Model\"], rotation=45, ha='right')\n",
    "plt.axhline(0.87, color='red', linewidth=2)\n",
    "\n",
    "plt.ylabel(\"Tikslumas\", fontsize=13)\n",
    "plt.title(\"ModeliÅ³ palyginimas pagal vektorizacijos metodus\", fontsize=15, pad=10)\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.axhline(y=0.87, color=\"red\", linestyle=\"--\", linewidth=1.5)\n",
    "plt.legend(title=\"Vektorizacija\", title_fontsize=12, fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "9181107e89c6220f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Ensemble",
   "id": "27b6ef7e919e679b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "base_models = [\n",
    "    ('Logistic Regression', LogisticRegression(max_iter=1000, random_state=5)),\n",
    "    ('Linear SVM', LinearSVC(random_state=5)),\n",
    "    ('Random Forest', RandomForestClassifier(n_estimators=200, random_state=5))\n",
    "]"
   ],
   "id": "77e7cfc428a0e8a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X, vectorizer = vectorize_text(df_sw, 'bow')\n",
    "y = df_sw['label'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)"
   ],
   "id": "92d9282555c220b2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "meta_model_svc = LogisticRegression(max_iter=1000, random_state=5)\n",
    "\n",
    "stack_svc = StackingClassifier(\n",
    "    estimators=base_models,\n",
    "    final_estimator=meta_model_svc,\n",
    "    passthrough=True,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "stack_svc.fit(X_train, y_train)\n",
    "y_pred = stack_svc.predict(X_test)\n",
    "\n",
    "print(\"âœ… Stacking tikslumas:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, digits=3))\n"
   ],
   "id": "a906824833cd98a6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "probas = stack_svc.predict_proba(X_test)\n",
    "spam_probas = probas[:, 1]\n",
    "threshold = 0.9  # pvz., 70% tikimybÄ—\n",
    "predictions = (spam_probas > threshold).astype(int)\n",
    "\n",
    "print(\"âœ… Stacking tikslumas:\", accuracy_score(y_test, predictions))\n",
    "print(classification_report(y_test, predictions, digits=3))\n"
   ],
   "id": "8387301cf1dba6df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cd82bfec160db09c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cb71565068286199"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "527738ceb8ecbe8a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ca3e5ee73f6c44f2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a4f5fb46c60886d7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "34da440914c1d74f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a9c13dc7cd91e9ad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "89853d0b8162b429"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "dce3c4a1ce726c04"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "387c5a4c8a3ec080"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "57a0136b2499861a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "37373c93184785ec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f4ad614d0c4aa5f0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "645741eb2867f6f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5dc9133865141d9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d74a6f1e6028865b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp_vu] *",
   "language": "python",
   "name": "conda-env-nlp_vu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
