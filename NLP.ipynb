{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Bibliotekos",
   "id": "bc0a40a13de1c732"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from nltk.chunk.named_entity import shape\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import spacy\n",
    "from sklearn.ensemble import StackingClassifier"
   ],
   "id": "9203d41ebcc31484"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Failo skaitymas",
   "id": "c8fbb5549ba19833"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# Perskaitome failƒÖ\n",
    "df = pd.read_csv(\"spam.csv\", encoding=\"latin-1\")\n",
    "\n",
    "df = df.iloc[:, :2]  # pasirenkam tik pirmus du stulpelius\n",
    "df.columns = ['label', 'text']  # pervadinam, jei reikia\n",
    "df['label'] = df['label'].str.lower()\n",
    "\n",
    "print(df.info())\n"
   ],
   "id": "862c4612583e87cb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df['label'] = df['label'].map({'spam': 1, 'ham': 0})\n",
    "\n",
    "print(df.head())"
   ],
   "id": "bedc942529f0447d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df['word_count'] = df['text'].apply(lambda x: len([w for w in str(x).split() if w.isalpha()]))\n",
    "\n",
    "\n",
    "df['char_count'] = df['text'].apply(lambda x: len(str(x).replace(\" \", \"\")))\n",
    "\n",
    "def plot_histograms(df, suffix=\"\"):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.histplot(df, x='word_count', hue='label', bins=30, kde=False, palette={0:'skyblue',1:'orange'})\n",
    "    plt.xlabel(\"≈Ωod≈æi≈≥ skaiƒçius\")\n",
    "    plt.ylabel(\"≈Ωinuƒçi≈≥ skaiƒçius\")\n",
    "    plt.title(f\"≈Ωinuƒçi≈≥ ilgiai (≈æod≈æiai) {suffix}\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.histplot(df, x='char_count', hue='label', bins=30, kde=False, palette={0:'skyblue',1:'orange'})\n",
    "    plt.xlabel(\"Simboli≈≥ skaiƒçius (be tarp≈≥)\")\n",
    "    plt.ylabel(\"≈Ωinuƒçi≈≥ skaiƒçius\")\n",
    "    plt.title(f\"≈Ωinuƒçi≈≥ ilgiai (simboliai) {suffix}\")\n",
    "    plt.show()\n",
    "\n",
    "plot_histograms(df, \"(original)\")\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "def plot_wordcloud(df, label, title):\n",
    "    text = \" \".join(df[df['label'] == label]['text'])\n",
    "\n",
    "    word_freq = Counter(text.split())\n",
    "\n",
    "    wc = WordCloud(\n",
    "        width=800,\n",
    "        height=400,\n",
    "        background_color='white',\n",
    "        colormap='Reds' if label == 1 else 'Blues'\n",
    "    ).generate_from_frequencies(word_freq)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_wordcloud(df, 1, \"Da≈æniausi ≈æod≈æiai SPAM\")\n",
    "plot_wordcloud(df, 0, \"Da≈æniausi ≈æod≈æiai HAM\")\n",
    "\n",
    "def get_top_words(df, label, n=20):\n",
    "    words = \" \".join(df[df['label']==label]['text']).split()\n",
    "    counter = Counter(words)\n",
    "    return counter.most_common(n)\n",
    "\n",
    "top_spam = get_top_words(df, 1)\n",
    "top_ham = get_top_words(df, 0)\n",
    "print(\"Top SPAM:\", top_spam)\n",
    "print(\"Top HAM:\", top_ham)"
   ],
   "id": "ebfb18bed40559b3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Sukuriame savo stop_words sƒÖra≈°ƒÖ\n",
    "my_stop_words = {\n",
    "    'the', 'a', 'an', 'and', 'or', 'in', 'on', 'of', 'to', 'for', 'is', 'are',\n",
    "    'was', 'were', 'be', 'been', 'it', 'this', 'that', 'with', 'as', 'by', 'at',\n",
    "    'from', 'about', 'into', 'up', 'out', 'so', 'if', 'then', 'but', 'you', 'your', 'have',\n",
    "    'u'\n",
    "}\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    words = str(text).lower().split()\n",
    "    filtered = [w for w in words if w not in my_stop_words]\n",
    "    return \" \".join(filtered)\n",
    "\n",
    "# Sukuriame kopijƒÖ ir pritaikome funkcijƒÖ\n",
    "df_sw = df.copy()\n",
    "df_sw['text'] = df_sw['text'].apply(remove_stopwords)\n"
   ],
   "id": "45ae0c2735fa77e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plot_histograms(df_sw, \"(be stopwords)\")\n",
    "plot_wordcloud(df_sw, 1, \"SPAM (be stopwords)\")\n",
    "plot_wordcloud(df_sw, 0, \"HAM (be stopwords)\")\n",
    "\n",
    "top_spam_sw = get_top_words(df_sw, 1)\n",
    "top_ham_sw = get_top_words(df_sw, 0)\n",
    "print(\"Top SPAM (be stopwords):\", top_spam_sw)\n",
    "print(\"Top HAM (be stopwords):\", top_ham_sw)\n"
   ],
   "id": "9c7c46f370ea564b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Vektorizavimas/mokymas\n",
   "id": "62fa7712a0020182"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Linear SVM\": LinearSVC(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=5),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5)\n",
    "}\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "def vectorize_text(df, method=\"bow\", vectorizer=None):\n",
    "    texts = df['text'].astype(str).tolist()\n",
    "\n",
    "    if method == \"bow\":\n",
    "        if vectorizer is None:\n",
    "            vectorizer = CountVectorizer()\n",
    "            X = vectorizer.fit_transform(texts)   # treniruojam + kuriam zodyna\n",
    "        else:\n",
    "            X = vectorizer.transform(texts)       # naudojam esama zodyna\n",
    "\n",
    "    elif method == \"tfidf\":\n",
    "        if vectorizer is None:\n",
    "            vectorizer = TfidfVectorizer()\n",
    "            X = vectorizer.fit_transform(texts)\n",
    "        else:\n",
    "            X = vectorizer.transform(texts)\n",
    "\n",
    "    elif method == \"spacy_w2v\":\n",
    "        # spacy nereikia vectorizer\n",
    "        X = np.array([nlp(t).vector for t in texts])\n",
    "        vectorizer = None\n",
    "    else:\n",
    "        raise ValueError(\"Ne≈æinomas metodas\")\n",
    "\n",
    "    return X, vectorizer\n",
    "\n",
    "def train_and_evaluate(models, X_train, X_test, y_train, y_test, title=\"\"):\n",
    "    results = []\n",
    "    print(f\"\\n=== {title} ===\")\n",
    "    for name, model in models.items():\n",
    "        print(f\"üîπ Treniruojamas: {name}\")\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        results.append((name, acc))\n",
    "        print(f\"‚úÖ Tikslumas: {acc:.4f}\")\n",
    "        print(classification_report(y_test, y_pred, digits=3))\n",
    "        print(\"-\"*50)\n",
    "    return pd.DataFrame(results, columns=[\"Model\", \"Accuracy\"]).sort_values(by=\"Accuracy\", ascending=False)\n",
    "\n",
    "def plot_results(df, title=\"\"):\n",
    "    df = df.sort_values(by=\"Accuracy\", ascending=True)\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.barh(df[\"Model\"], df[\"Accuracy\"], color='skyblue')\n",
    "    for i, v in enumerate(df[\"Accuracy\"]):\n",
    "        plt.text(v + 0.002, i, f\"{v:.3f}\", va='center')\n",
    "    plt.xlabel(\"Tikslumas\")\n",
    "    plt.title(title)\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
    "    plt.show()"
   ],
   "id": "4a8f0c6c63bd9628"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train/Test padalinimas bei mokymas",
   "id": "1da69e173188a709"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "y = df['label'].values\n",
    "results_all = {}\n",
    "for method in [\"bow\", \"tfidf\", \"spacy_w2v\"]:\n",
    "    print(f\"\\n\\n### Vektorizacija: {method.upper()} ###\")\n",
    "    for data, label in [(df, \"original\"), (df_sw, \"no_stopwords\")]:\n",
    "        X, vectorizer = vectorize_text(data, method)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)\n",
    "        results = train_and_evaluate(models, X_train, X_test, y_train, y_test, title=f\"{method.upper()} - {label}\")\n",
    "        results_all[f\"{method}_{label}\"] = results\n",
    "        plot_results(results, title=f\"{method.upper()} - {label}\")"
   ],
   "id": "1e490113f2b50d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "comparison_df = pd.DataFrame({\"Model\": list(models.keys())})\n",
    "for key, df_res in results_all.items():\n",
    "    comparison_df = comparison_df.merge(df_res, on=\"Model\", how=\"left\", suffixes=(\"\", f\"_{key}\"))\n",
    "\n",
    "comparison_df.columns = [\"Model\"] + [f\"Accuracy_{k}\" for k in results_all.keys()]\n",
    "\n",
    "x = np.arange(len(comparison_df))\n",
    "width = 0.12\n",
    "plt.figure(figsize=(15, 7))\n",
    "\n",
    "# Gra≈æesnƒó spalv≈≥ paletƒó\n",
    "colors = [\"#4C72B0\", \"#55A868\", \"#C44E52\", \"#8172B2\", \"#CCB974\", \"#64B5CD\"]\n",
    "\n",
    "n_models = len(comparison_df)\n",
    "n_methods = len(comparison_df.columns) - 1\n",
    "x = np.arange(n_models)\n",
    "width = 0.8 / n_methods\n",
    "\n",
    "for i, col in enumerate(comparison_df.columns[1:]):\n",
    "    plt.bar(\n",
    "        x + i * width - (width * (n_methods - 1) / 2),\n",
    "        comparison_df[col],\n",
    "        width,\n",
    "        label=col.replace(\"Accuracy_\", \"\").upper(),  # <-- FIX\n",
    "        alpha=0.9,\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=0.7,\n",
    "        color=colors[i % len(colors)]               # <-- spalvos dabar veiks\n",
    "    )\n",
    "\n",
    "\n",
    "plt.xticks(x, comparison_df[\"Model\"], rotation=45, ha='right')\n",
    "plt.ylabel(\"Tikslumas\", fontsize=13)\n",
    "plt.title(\"Modeli≈≥ palyginimas pagal vektorizacijos metodus\", fontsize=15, pad=10)\n",
    "plt.ylim(0, 1.05)\n",
    "\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.legend(title=\"Vektorizacija\", title_fontsize=12, fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "f1b9cca23b8b59d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Ensemble",
   "id": "d135d6f8de7979ca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "base_models = [\n",
    "    ('Logistic Regression', LogisticRegression(max_iter=1000, random_state=5)),\n",
    "    ('Linear SVM', LinearSVC(random_state=5)),\n",
    "    ('Random Forest', RandomForestClassifier(n_estimators=200, random_state=5))\n",
    "]"
   ],
   "id": "e487d0df0d72e6f8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X, vectorizer = vectorize_text(df, 'bow')\n",
    "y = df['label'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)"
   ],
   "id": "dafad917643de33d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "meta_model_svc = LogisticRegression(max_iter=1000, random_state=5)\n",
    "\n",
    "stack_svc = StackingClassifier(\n",
    "    estimators=base_models,\n",
    "    final_estimator=meta_model_svc,\n",
    "    passthrough=False,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "stack_svc.fit(X_train, y_train)\n",
    "y_pred = stack_svc.predict(X_test)\n",
    "\n",
    "print(\"‚úÖ Stacking tikslumas:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, digits=3))\n"
   ],
   "id": "629e555576874c69"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "607bcb0aeceed243"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Testavimas su https://archive.ics.uci.edu/dataset/228/sms+spam+collection",
   "id": "7e838e28330dc7f3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data = pd.read_csv('SMSSpamCollection',delimiter=\"\\t\",header=None)\n",
    "data.columns = [\"label\",\"text\"]\n",
    "\n",
    "data['label'] = data['label'].map({'spam': 1, 'ham': 0})"
   ],
   "id": "a4962ec7a70d4d06"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X_df, vectorizer = vectorize_text(df, 'tfidf', vectorizer = vectorizer)\n",
    "\n",
    "X_data, vectorizer = vectorize_text(data, 'tfidf', vectorizer = vectorizer)"
   ],
   "id": "d8245fc234c6a575"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "stack_svc.fit(X_df, df['label'])\n",
    "\n",
    "y_pred_data = stack_svc.predict(X_data)\n",
    "\n",
    "print(accuracy_score(data['label'], y_pred_data))"
   ],
   "id": "7419f25ea3c5b52d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c144b44de1df9602"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1f3c105e8e22e937"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f6d9f401558b366c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9ba8549654ee648c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9535bfb8162be93a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9184e4c496545501"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9a476b244f67541f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "75bf333f3af60dfe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a788166a74a2d6cf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "657bcb015721c53f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ec385cc1037c70d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "34103c170c8730e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "61f511a03584c4c3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "21362de89ae4238f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "229b627709ded84a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "791ac1f94d7b7a17"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "df7ef3c93033d756"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp_vu] *",
   "language": "python",
   "name": "conda-env-nlp_vu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
